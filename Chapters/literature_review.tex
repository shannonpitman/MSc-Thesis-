\chapter{Literature Review}
\label{chap:litreview}
The effectiveness of indoor localisation systems depends on the strategic positioning of the sensor network. Depending on the application, the distribution may need to prioritise coverage of a large space with sufficiently distinct viewpoints to capture elaborate motion, or it may need to be configured to mitigate the Geometric Dilution of Precision (GDOP) arising from the sensor network's limited resolution \parencite{kirchhofOptimalPlacementMultiple2013}. The placement problem constitutes an optimisation task involving determination of both the quantity and pose of sensors so as to improve measurement quality by minimising the inherent uncertainty. This section explores the principal approaches to the Optimal Camera Placement (OCP) problem, examining both the characterisation of sources of inherent uncertainty, attributable to image quantisation and occlusion of the target, and strategies for addressing them, as well as the range of optimisation methods employed, from heuristic algorithms to integer programming.


\section{Optimising Camera Placement}
The OCP descends from the well-studied Art Gallery Problem (AGP), which investigated the minimum number of guards required to observe an entire 2D polygon with $n$ vertices. The AGP assumed guards had unlimited $360 \degree$ field of view, infinite range, and operated in two dimensions only. Fisk elegantly proved that $\lfloor\frac{n}{3}\rfloor$ guards are always sufficient to cover any simple polygon, using a proof based on triangulation and 3-colouring; in practice, specific polygons often require fewer, as demonstrated in Figure~\ref{fig:fisk} \parencite{fiskArtGalleryProblem1978}. In this example, a polygon with $n=13$ vertices is first triangulated, then each vertex is assigned one of three colours such that no triangle shares two vertices of the same colour; placing guards at all vertices of the least frequent colour guarantees complete coverage. The optimal camera placement problem extends this foundation by introducing constraints that reflect the true capabilities and limitations of physical sensors.

These constraints are motivated by diverse applications: surveillance and monitoring \parencite{bodorOptimalCameraPlacement2007}, motion capture \parencite{aissaouiDesigningCameraPlacement2018, zieglerOptimalCameraPlacement2023}, augmented and virtual reality \parencite{rahimianOptimalCameraPlacement2017}, and autonomous driving \parencite{puligandlaMultiresolutionApproachLarge2022}. In such visual sensor networks, accurate localisation requires that each marker or feature be visible to at least two cameras, enabling 3D position recovery through triangulation \parencite{aissaouiDesigningCameraPlacement2018,zieglerOptimalCameraPlacement2023}. Sensor placement (including amount, location, and orientation) significantly affects system coverage and tracking performance \parencite{zhouSensorPlacementOptimization2024}. However, the OCP is NP-hard and combinatorial: the search space grows explosively with the number of candidate positions and orientations, rendering exhaustive search intractable. Consequently, heuristic-based approximation algorithms offer a practical path to acceptable solutions within reasonable computation time.

Generally, the OCP can be stated as follows: given a set of candidate camera locations and orientations, find the configuration that maximises 3D reconstruction quality of a target within a defined workspace, subject to practical constraints such as mounting options and budget. Solving this problem requires balancing trade-offs among coverage, accuracy, and computational efficiency. Without the aid of an optimisation algorithm, the sensors are arranged in an ad-hoc configuration by the designer, which requires expertise or trial and error, which can be time-consuming or sacrificial if a sub-par arrangement is settled on. Thus the resulting localisation error is neither calculated nor considered mathematically. Thus, there is a need to optimise the camera netwrok based on metrics that minimise the effects of resolution degredation and probabilistic occlusion even if the trajectory of the target is not known exactly beforehand.

\subsection{Optimisation Approaches for Camera Placement}


Objectives of Optimization
The configuration quality for 3D marker tracking and trinagulation is mostly affected y two main sources of error: marker visibility and triangulation accuracy. A marker should not be occluded by any obstacle, including itself, the marker must be within the cameras field of view, vissible given the camera's resolution and range of capture. At least two cameras should be arranged sufficiently non-parallel so that triangulation is well-conditioned. The least amount of cameras is required to achieve this to minimise cost.  
- what has research optimised for: coverage based objectives (minimise blind spots, maximise visible area) vs accuracy-based (3D reconstruction quality, minimise resolution degredation, trinangulation accuracy).
- Diagram for triangulation + definition (show that if the cameras are opposite eachother how the uncertainty increases for the localisation by the geometric dilution of precision (GDOP))
- Need a quality measure to rank valid solutions  



Different Methods to achieve and find an optimised camera config 
Prior research has focused on two main factors that contribute to unaccurate reconstruction (1) minimise error due to inaccurate triangulation and (2) placing cameras to provide the best views in the presence of occlusion. 
- synthesis of how field developed 
- timeline 
- comparison of different approaches 
- thematic overview of developing approaches and literature comparison
Resolution:
Wu, Sharma, and Huang introduced the intersection of projected pyramids to present a  numerical measurement of uncertainty bounds. 
Aissaoui 


Occlusion
Chen and Davis: introduce the probabilistic model of occlusion
Rahimian et al: convergence angle of cameras 

- table cols [Method | Literature | Problem Scale | Pros | Cons ], rows: Heuristics: (GA, PSO, SA) Integer Programming (Branch and bound) 
- Make choice of GA defensible by comaprison 

What I specifically took from each paper, why -> how it connects to my work 
examples of multi-objective camera placement 

research gap -> few incorporate realistic occlusion models 
no open-source implementation 

Contribution Statement: integrates res uncertainty (3D-ellipsoid) with dynamic occlusion. real-doded GA with guided initialisation validated against an OptiTrack commercial system 


Justification of the GA:
- is not prone to getting stuck in local optima as the Greedy Algorithm, due to the randomness introduced in several parts of the algorithm. Crossover method favours the parent with he highest fitness but still introduces randomness for children both inheriting genes from a weaker parent or in the mutation process that follows. 


Method:
- user to specify the number of cameras and possible camera locations for placement (mounting)
- parallel processing 
- we empirically test the methods against the ad hoc placement of the OptiTrack system in our laboratory - which was designed for a specific capture volume 
- placement based on optimising for visibility without considering robustness to dynamic occlusion
- placement based solely on robustness to occlusion without regard for degrading resolution
- a combined cost function of the two concerns 
- chose a 6 parameter representation at it is the minimum required number needed to specify the position and orientation of a rigid body in 3D space. 
- camera model: used Peter Corke's CentralCamera which is a central-projecton perspective camera, a subclass of Camera. The coordinate system is X (right), Y (down), and z-axis is into the page aligning with the optical axis of the camera as seen below [insert image]. I inputted the parameters from the OpenMV camera sensor datasheet as inputs, I neglected both radial and tangental distortion which is reasonable considerimg the lens tech available today and with proper camera calibration. The sensor, $$C$$ is defined by a (insert number of inputs) I placed into the central camera -tuple $$[\hat{T_c}, N_c, f_c, S_c, P_c].$$ Where $$T_c$$ is the pose, as a homogenous transformation, of the camera in space. $$N_c$$ is the image plane resolution, $$f_c$$ the focal length in meters, $$S_c$$ is the pixel size, and $$P_c$$ is the principle point of the camera. The sensing range was determined experimentally.
- Coverage/line of sight: 
1. The Euclidian distance between the camera $$C$$ to the point $$i$$ is smaller than, or equal to, the sensing range of the camera $$c$$
2. The angle between the camera $$C$$ and the point i is the field of view of the sensor 
- The genetic algorithm developed here is guided: initial population, as well as an uodated mutation step every 10 iterations to reorient any cameras that may have mutate to face outwards form the workspace. 

subsection- Algorithm design
Given the number of sensors, mounting constraints, size and modality of workspace/ flight envelope, how many data points can be covered whilst mitigating the effects of resolution degradation and ensuring redundancy against dynamic occlusion.  Real-coded 
Explain camera chromosome, gene and population [insert image]
\textbf{Initialisation} 
User-determined population size
feasible faces of where the cameras can be mounted [insert picture of box around the flight envelope] 
The flight envelope is partitioned based on the user specified amount of cameras [insert picture here as well]
A face is randomly selected and then the camera is z-axis is oriented to face towards the section centre closest to where the camera is located.

\textbf{Parent Selection Scheme}
Selection probability is proportional to the better individuals 
Roulette wheel- is conservative and has a significant selection pressure, there exist other methods like Tournament selection.
If the selection pressure is too high, the algorithm may be stuck in local optima, and if the selection pressure is too low, the algorithm becomes very random and struggles to progress. This makes the design of a selection scheme an essential aspect of the GA design.
Probability is determined by the Boltzmann rule distribution  $$p_i \propto exp(\frac{- \epsilon_i}{k_B*T} )$$

\textbf{Crossover}
Double-point crossover

\textbf{Mutation}
Provides the randomness of the child that promotes diversity in the population
Every ten iterations the orientations are checked to see if they are seeing too few points (i.e is hey are facing away from the workspace or have been angled to be tangential to a face) if this is the case they are reoriented by the same methodology used in the initial population where they are pointed towards the section centre closest to them.
Similarly, after mutation the bounds are checked from position to ensure that the cameras havent mutated to be out of the workspace mounting faces.

\textbf{Elitism}
Two population of children and parents are recombined to the original population size ensuring monotonic convergence 

\textbf{Cost Functions}
\textbf{Resolution Uncertainty}
\textbf{Dynamic occlusion}





















% The literature review establishes the theoretical and practical foundation for your engineering investigation. This chapter demonstrates your understanding of the current state of knowledge in your field, critically evaluates existing solutions, and identifies the specific gap that justifies your project. Unlike a simple summary of sources, an engineering literature review synthesises prior work to build a compelling case for your approach and methodology.

% A well-structured literature review serves multiple purposes: it positions your work within the broader engineering context, demonstrates awareness of existing solutions and their limitations, provides evidence for design decisions, and establishes credibility through engagement with peer-reviewed sources. This chapter should guide the reader from general background knowledge to the specific problem your project addresses.

% \section{Typical Structure and Content}

% An effective engineering literature review typically includes the following elements:

% \begin{itemize}
% \item \textbf{Scope and search strategy}: Define the boundaries of your review and explain how you identified relevant sources.
% \item \textbf{Thematic synthesis of prior work}: Organise literature around key themes, technologies, or approaches rather than chronologically.
% \item \textbf{Comparative analysis}: Systematically compare methods, performance metrics, and limitations across different approaches.
% \item \textbf{Technical evaluation}: Assess the engineering merit of different solutions, including scalability, reliability, and practical constraints.
% \item \textbf{Identified research or practice gap}: Clearly articulate what remains unsolved or inadequately addressed.
% \item \textbf{Implications for your methodology}: Connect the literature directly to your design choices and experimental approach
% \end{itemize}

% \section{Citation Practice and Source Integration}

% Use the \texttt{natbib} package commands to integrate sources naturally into your technical narrative. For example, \cite{ryalat_integration_2024} demonstrated the integration of mechatronic systems in Industry 4.0 applications, while comparative studies \cite{phad} have shown the benefits of cyber-physical system approaches. 

% Organise complex comparisons using tables, such as Table \ref{tab:lit-taxonomy} below, to help readers understand the landscape of existing solutions:

% \begin{table}[h]
% \centering
% \caption{Example taxonomy of mechatronic system approaches in modern engineering applications.}
% \begin{tabular}{p{2.5cm}p{2.5cm}p{2.5cm}p{2.5cm}}
% \toprule 
% Approach & Application Domain & Key Technology & Performance Metric \\
% \midrule 
% Smart Manufacturing & Industrial & IoT + AI & Efficiency (\%) \\
% Soft Robotics & Automation & Advanced Materials & Flexibility \\
% Cyber-Physical Systems & Integration & Real-time Control & Response Time (ms) \\
% \bottomrule
% \end{tabular}
% \label{tab:lit-taxonomy}
% \end{table}

% \section{Critical Analysis and Research Gap}

% The literature review should culminate in a clear identification of the gap your project addresses. This gap might be a technical limitation in existing solutions, an unexplored application domain, a need for improved performance metrics, or insufficient validation under realistic operating conditions. 

% Articulate how the limitations and strengths identified in the literature directly inform your project objectives and methodology choices. This connection ensures that your approach is grounded in evidence and addresses a genuine need.